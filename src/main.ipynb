{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Amann(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Amann is a neueral network for detecting amharic characters. \n",
    "        It does so by first resizing the image to 28x28 and then\n",
    "        applying multiple layers of convolution and pooling, finishing with\n",
    "        a linear layer.\n",
    "        \n",
    "        In Amharic there are 34 base characters each with 7 children. Thus the \n",
    "        end layer will have 34*7 = 238 outputs.\n",
    "        \n",
    "        One top of the neural network it has a regulairization layer to prevent\n",
    "        the small kernels from overfitting.\n",
    "        \"\"\"\n",
    "        super(Amann, self).__init__()\n",
    "        \n",
    "        \n",
    "        # convolution layers   \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=9, stride=1, padding=4)\n",
    "        \n",
    "        \n",
    "        # pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        \n",
    "        # linear layer\n",
    "        self.linear = nn.Linear(64*3*3, 34)\n",
    "        self.linear2 = nn.Linear(34, 238)\n",
    "        \n",
    "        # regularization layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # convolution layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # linear layers\n",
    "        x = x.view(-1, 64*3*3)\n",
    "        x = F.relu(self.linear(x))\n",
    "        #x = self.dropout(F.relu(self.linear(x)))\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmharicDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_filenames = os.listdir(data_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_filenames[idx]\n",
    "        image = Image.open(os.path.join(self.data_dir, filename)).convert('L')\n",
    "        image = transforms.ToTensor()(image)\n",
    "        # Convert the image to grayscale using .convert('L')\n",
    "        label = int(filename.split('.')[0])\n",
    "        return image, label - 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dataset, train the model, and save the model\n",
    "\n",
    "data_dir = \"../dataset/\"\n",
    "dataset = AmharicDataset(data_dir)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=80, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=80, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 5.478\n",
      "[1,   200] loss: 5.473\n",
      "[1,   300] loss: 5.451\n",
      "[2,   100] loss: 5.290\n",
      "[2,   200] loss: 5.053\n",
      "[2,   300] loss: 4.748\n",
      "[3,   100] loss: 4.154\n",
      "[3,   200] loss: 3.908\n",
      "[3,   300] loss: 3.628\n",
      "[4,   100] loss: 3.261\n",
      "[4,   200] loss: 3.128\n",
      "[4,   300] loss: 2.982\n",
      "[5,   100] loss: 2.706\n",
      "[5,   200] loss: 2.644\n",
      "[5,   300] loss: 2.580\n",
      "[6,   100] loss: 2.377\n",
      "[6,   200] loss: 2.331\n",
      "[6,   300] loss: 2.275\n",
      "[7,   100] loss: 2.124\n",
      "[7,   200] loss: 2.120\n",
      "[7,   300] loss: 2.072\n",
      "[8,   100] loss: 2.007\n",
      "[8,   200] loss: 1.957\n",
      "[8,   300] loss: 1.912\n",
      "[9,   100] loss: 1.812\n",
      "[9,   200] loss: 1.829\n",
      "[9,   300] loss: 1.820\n",
      "[10,   100] loss: 1.718\n",
      "[10,   200] loss: 1.725\n",
      "[10,   300] loss: 1.726\n",
      "[11,   100] loss: 1.632\n",
      "[11,   200] loss: 1.650\n",
      "[11,   300] loss: 1.642\n",
      "[12,   100] loss: 1.567\n",
      "[12,   200] loss: 1.600\n",
      "[12,   300] loss: 1.572\n",
      "[13,   100] loss: 1.494\n",
      "[13,   200] loss: 1.521\n",
      "[13,   300] loss: 1.495\n",
      "[14,   100] loss: 1.448\n",
      "[14,   200] loss: 1.423\n",
      "[14,   300] loss: 1.460\n",
      "[15,   100] loss: 1.386\n",
      "[15,   200] loss: 1.396\n",
      "[15,   300] loss: 1.415\n",
      "[16,   100] loss: 1.344\n",
      "[16,   200] loss: 1.348\n",
      "[16,   300] loss: 1.362\n",
      "[17,   100] loss: 1.311\n",
      "[17,   200] loss: 1.339\n",
      "[17,   300] loss: 1.313\n",
      "[18,   100] loss: 1.284\n",
      "[18,   200] loss: 1.280\n",
      "[18,   300] loss: 1.326\n",
      "[19,   100] loss: 1.271\n",
      "[19,   200] loss: 1.277\n",
      "[19,   300] loss: 1.259\n",
      "[20,   100] loss: 1.232\n",
      "[20,   200] loss: 1.226\n",
      "[20,   300] loss: 1.233\n",
      "[21,   100] loss: 1.183\n",
      "[21,   200] loss: 1.215\n",
      "[21,   300] loss: 1.198\n",
      "[22,   100] loss: 1.175\n",
      "[22,   200] loss: 1.149\n",
      "[22,   300] loss: 1.178\n",
      "[23,   100] loss: 1.153\n",
      "[23,   200] loss: 1.177\n"
     ]
    }
   ],
   "source": [
    "model = Amann()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimzer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimzer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        # print(\"input shape\", inputs.shape, outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 72.87%\n"
     ]
    }
   ],
   "source": [
    "# pandas dataframe to load the csv map file\n",
    "df = pd.read_csv(\"../supported_chars.csv\")\n",
    "prop = FontProperties()\n",
    "prop.set_file(\"../Fonts/NotoSerif.ttf\")\n",
    "    \n",
    "\n",
    "#test model accuracy\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over test dataset\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Pass input through model to get predictions\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update total count and correct count\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Visualize input with image viewer along with the prediction\n",
    "        # for i in range(inputs.size(0)):\n",
    "        #     image = inputs[i].numpy()\n",
    "        #     is_correct = predicted[i].item() == labels[i].item()\n",
    "            \n",
    "        #     label_str = \"Correct\" if is_correct else \"Mistaken\"\n",
    "        #     character = df[\"Character\"][labels[i].item()]\n",
    "        #     predicted_char = df[\"Character\"][predicted[i].item()]\n",
    "            \n",
    "        #     # Save test results\n",
    "        #     plt.imshow(np.squeeze(image), cmap='gray')\n",
    "        #     plt.title(f\"{label_str}: Actual -> {character}, predicted -> {predicted_char}\", fontproperties=prop)\n",
    "        #     plt.savefig(f\"../test_results/{label_str}_{i}_{correct}.png\")\n",
    "                \n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy on test set: {:.2f}%'.format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to disk\n",
    "torch.save(model.state_dict(), \"amann.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Warning:model is Amann(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear): Linear(in_features=1568, out_features=238, bias=True)\n",
      "  (linear2): Linear(in_features=238, out_features=34, bias=True)\n",
      "  (linear3): Linear(in_features=34, out_features=238, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "                        Proper storage of interactively declared classes (or instances\n",
      "                        of those classes) is not possible! Only instances\n",
      "                        of classes in real modules on file system can be %store'd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%store model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
